# CS155: Homework 6

## Problem 1

**a.**

The VC-dimension of $([0,1], R)$ is $4$. 

We first show four points can be shattered by $R$ by considering $\{0,1/4,1/2, 3/4\}$.

- $\empty$: $[0.1,0.2] \cup [0.3,0.4]$
- Singletons: $[0,0.1] \cup [0.1,0.2]$ and similar ones with one interval containing each singleton and another one disjoint from the set
- Two elements: $[0,0.1] \cup [0.2,0.3]$ and similar ones with two disjoint intervals, each containing exactly one element
- Three elements: $[0,0.1] \cup [0.4,1]$ and similar ones. Two of the three points will be consecutive and we can take one interval containing these two and another disjoint interval containing the last point.
- All four: $[0,1] \cup [0,1]$

Next we show that any set of five distinct points can't be shattered by $R$. Given a set of five distinct points $S = \{x_1,...,x_5\}$ with
$$
x_1 < x_2 <...<x_5.
$$
We claim that the projection of $R$ can't contain the set $\{x_1,x_3,x_5\}$. Suppose we have two intervals $I_1 \cup I_2$ such that $(I_1 \cup I_2) \cap S = \{x_1,x_3,x_5\}$. We know two of the three points $x_i,x_j$ are in the same interval, say $I_1$. Therefore, $I_1$ will also contain any point $x_k$ such that $i \leq k \leq j$, which is a contradiction.



**b.**

Given $\epsilon > 0$, we define an integer $n$ by 
$$
n = \mathrm{ceil}(2/\epsilon)
$$
and a set 
$$
S = \{\frac{i}{n}:i=0,...,n\}.
$$
We have $|S| = n+1$. Given any $I_1, I_2 \subset [0,1]$ such that
$$
P_D(I_1 \cup I_2) > \epsilon.
$$
We know at least one of them has probability at least $\epsilon /2$. Without loss, let's assume
$$
P_D(I_1) = P_D([a_1,b_1]) = b_1 - a_1 > \epsilon/2 > 1/n.
$$
This implies that $[a_1, b_1]$ will contain an element of $S$. Therefore, $S$ is an $\epsilon$-net of $([0,1],R)$ with respect to the uniform distribution.



**c.**

We can use a similar construction as above with
$$
S = \{\frac{i}{n}: i=0,...,n\}
$$
for some properly chosen $n$. Given any interval $I$ of size $l$ such that
$$
\frac{k}{n} \leq l < \frac{k+1}{n},
$$
we know
$$
k \leq |I \cap S| \leq k+1. 
$$
Therefore
$$
\frac{k}{n+1} \leq \frac{|I \cap S|}{|S|} \leq \frac{k+1}{n+1}
$$
and
$$
\frac{k}{n} - \frac{k}{n+1}\leq l - \frac{k}{n+1}\leq P_D(I) - \frac{|I \cap S|}{|S|} \leq l - \frac{k}{n+1} < \frac{k+1}{n} - \frac{k+1}{n+1}.
$$
Therefore, 
$$
|P_D(I) - \frac{|I \cap S|}{|S|}| \leq \frac{k+1}{n(n+1)} \leq \frac{1}{n}.
$$
Given a union of two intervals, $I_1 \cup I_2$, if $I_1 \cap I_2 \neq \empty$, we can view them as a single closed interval and the above bound holds. If $I_1 \cup I_2 = \empty$, we can use the triangle inequality:
$$
P(I_1 \cup I_2) = P(I_1) + P(I_2)
$$

$$
(I_1 \cup I_2) \cap S = (I_1 \cap S) \cup (I_2 \cap S)
$$

$$
|P(I_1) - \frac{|I_1\cap S| }{|S|} + P(I_2) - \frac{|I_2 \cap S|}{|S|}| \leq \frac{2}{n}.
$$

And picking
$$
n = \mathrm{ceil}(2/\epsilon)
$$
is again enough to make $S$ an $\epsilon$-sample.



**c.**

Asymptotically, the size of $S$ is
$$
|S| = O(\frac{2}{\epsilon}),
$$
which is smaller than the bounds for the $\epsilon$-net
$$
O(\frac{4}{\epsilon}\ln \frac{4}{\epsilon} + \cdot).
$$
The bound for $\epsilon$-sample is bigger and thus is trivial to verify.



## Problem 2

**a.**

The VC-dimension of $(X,R)$ is $2$. We can follow a very similar argument as for one-dimensional intervals. Given a set of two elements $\{1,2\}$, it can be shattered by $R$:

- $\empty$: $[3,4]$
- Singleton: $[i,i]$, $i=1,2$
- Full set: $[1,2]$

Given any set of three points $\{i,j,k\}$ with $i<j<k$, any element of $R$ containing $i,k$ will contain $j$ and therefore $\{i,k\}$ is not in the projection of $R$. So $R$ can't shatter any set of three distinct points.



**b.**

We can construct an $\epsilon$-net for $(X,R)$ by considering the set
$$
S = \{1,...,k\}
$$
for some properly chosen $k$:
$$
k > -\log_2\epsilon
$$
Given any set $Y \subset X$ such that $P(Y) > \epsilon$, we know $Y \cap S \neq \empty$ because
$$
P(Y \cap S) = P(Y) - P(Y \cap \bar{S}) \geq P(Y) - P(\bar{S}) = P(Y) - 2^{-k}>0
$$
by our definition of $k$.

Therefore $S$ is an $\epsilon$-net for $(X,R)$ with
$$
|S| = O(\log_2 \frac{1}{\epsilon}) = O(\frac{1}{\ln2}\ln\frac{1}{\epsilon}).
$$


**c.**

We can consider a set of similar form as in **part b**:
$$
S = \{1,...,k\}
$$
for some properly chosen $k$.

Given any set $Y \subset X$, we have
$$
P(Y) - 2^{-k} < P(Y\cap S) \leq P(Y).
$$
Therefore
$$
\frac{P(Y)-2^{-k}}{1-2^{-k}}\leq \frac{P(Y\cap S)}{P(S)} \leq \frac{P(Y)}{1-2^{-k}}
$$
and
$$
\begin{align}
|P(Y) - \frac{P(Y\cap S)}{P(S)}| &\leq |P(Y)||1-\frac{1}{1-2^{-k}}| + |\frac{2^{-k}}{1-2^{-k}}| \\
&\leq 2^{-(k-1)}\frac{1}{1-2^{-k}} \\
&\leq 2^{-(k-2)}.
\end{align}
$$
By choosing $k$ such that
$$
k > -\log_2 \epsilon + 2,
$$
the set $S$ will become an $\epsilon$-sample for $(X,R)$ with size
$$
|S| = O(\frac{1}{\ln2}\ln \frac{1}{\epsilon}).
$$


**c.**

Both of the sizes are smaller than the bound for a random sample size to achieve $\epsilon$-net:
$$
O(\frac{2}{\epsilon}\ln \frac{2}{\epsilon} + \cdot).
$$
